import os
import torch
import numpy as np
import gradio as gr
from scipy.io.wavfile import write as write_wav
import warnings

from ruaccent import RUAccent
from silero import silero_tts
from openvoice import se_extractor
from openvoice.api import ToneColorConverter

warnings.filterwarnings("ignore")

# --------------------
# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ –ø—É—Ç–∏
# --------------------
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
DEVICE_STR = "cuda" if DEVICE.type == "cuda" else "cpu"
OUTPUT_DIR = "outputs"
TEMP_DIR = os.path.join(OUTPUT_DIR, "temp")
TEMP_COLORS = os.path.join(TEMP_DIR, "colors")
BASE_SE_DIR = "checkpoints/base_speakers/RU_SILERO"
CONVERTER_CFG = "checkpoints/converter/config.json"
CONVERTER_CKPT = "checkpoints/converter/checkpoint.pth"
REF_TEXT = (
    "–ü—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –ø–æ—Ä–∞ –∏ –º–∞–π—Å–∫–∏–π –¥–µ–Ω—å –¥–æ–∂–¥–ª–∏–≤—ã–π. –°–∏–∂—É —É –æ–∫–Ω–∞ –∏ —á—É–≤—Å—Ç–≤—É—é –∞—Ä–æ–º–∞—Ç. "
    "–Ø –≤—Å–ø–æ–º–∏–Ω–∞—é —Å —Ä–∞–¥–æ—Å—Ç—å—é —Å–µ–≥–æ–¥–Ω—è—à–Ω—é—é –≤—Å—Ç—Ä–µ—á—É, –∏ —Å–µ—Ä–¥—Ü–µ –±—å—ë—Ç—Å—è –≤ —É–ø–æ–µ–Ω–∏–∏. "
    "–°–ª—ã—à—É –≥–æ–ª–æ—Å, —Å–º–æ—Ç—Ä—é –Ω–∞ –±—É–∫–µ—Ç. –Ø –≤ —ç–π—Ñ–æ—Ä–∏–∏! –°–Ω–æ–≤–∞ –≤–¥—ã—Ö–∞—é –∑–∞–ø–∞—Ö —Å–∏—Ä–µ–Ω–∏. "
    "–í—á–∏—Ç—ã–≤–∞—é—Å—å –≤ –ø–∏—Å—å–º–æ. –ü–æ—Å–ª–µ –∑–∞–º–∏—Ä–∞—é. –û—à–∏–±–∫–∞ –≤ –∏–º–µ–Ω–∏. –û–¥–Ω–∞ –±—É–∫–≤–∞. –ü–∏—Å—å–º–æ —Å–µ—Å—Ç—Ä–µ! "
    "–ú–≥–Ω–æ–≤–µ–Ω–Ω–æ –≤—ã—Å—Ç—É–ø–∏–≤—à–∏–µ —Å–ª—ë–∑—ã."
)
SAMPLE_RATE = 48000
SPEAKER = "kseniya"
LANGUAGE = "ru"

# --------------------
# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞–ø–æ–∫
# --------------------
for path in (OUTPUT_DIR, TEMP_DIR, TEMP_COLORS, BASE_SE_DIR):
    os.makedirs(path, exist_ok=True)

# --------------------
# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
# --------------------
print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ ToneColorConverter...")
tone_color_converter = ToneColorConverter(CONVERTER_CFG, device=DEVICE_STR)
tone_color_converter.load_ckpt(CONVERTER_CKPT)

print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ Silero TTS...")
hub_out = torch.hub.load(
    repo_or_dir="snakers4/silero-models",
    model="silero_tts",
    language=LANGUAGE,
    speaker=f"v3_1_{LANGUAGE}",
    device=DEVICE_STR
)
silero_model = hub_out[0] if isinstance(hub_out, (tuple, list)) else hub_out

print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ RUAccent...")
accent_model = RUAccent()
accent_model.load(omograph_model_size="big_poetry", use_dictionary=True)

# --------------------
# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ —Ç–µ–º–±—Ä–∞
# --------------------
source_se_path = os.path.join(BASE_SE_DIR, f"ru_{SPEAKER}_se.pth")
if not os.path.exists(source_se_path):
    print(f"‚ú® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ —Ç–µ–º–±—Ä–∞ –¥–ª—è `{SPEAKER}`...")
    ref_wav = os.path.join(TEMP_DIR, "reference_silero.wav")
    silero_model.save_wav(
        text=REF_TEXT,
        speaker=SPEAKER,
        sample_rate=SAMPLE_RATE,
        audio_path=ref_wav
    )
    se, _ = se_extractor.get_se(
        ref_wav,
        tone_color_converter,
        target_dir=TEMP_COLORS,
        vad=True
    )
    torch.save(se, source_se_path)
    print(f"‚úÖ –≠—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ–º–±—Ä —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {source_se_path}")

source_se = torch.load(source_se_path, map_location=DEVICE).to(DEVICE)
print("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –∏ —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ–º–±—Ä –≥–æ—Ç–æ–≤—ã.")

# --------------------
# –§—É–Ω–∫—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
# --------------------
def accent_text(text: str) -> str:
    """–†–∞—Å—Å—Ç–∞–≤–ª—è–µ—Ç —É–¥–∞—Ä–µ–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–µ."""
    if not text.strip():
        return ""
    return accent_model.process_all(text)

def generate_voice(accented_text: str, reference_audio: tuple) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞."""
    if not accented_text:
        raise gr.Error("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞.")
    if reference_audio is None:
        raise gr.Error("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∞—É–¥–∏–æ-—Ä–µ—Ñ–µ—Ä–µ–Ω—Å (5‚Äì15 —Å–µ–∫, WAV –±–µ–∑ —à—É–º–∞).")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞
    sr, audio_np = reference_audio
    ref_path = os.path.join(TEMP_DIR, "user_reference.wav")

    if audio_np.dtype != np.int16:
        audio_np = audio_np / np.max(np.abs(audio_np))
        write_wav(ref_path, sr, (audio_np * 32767).astype(np.int16))
    else:
        write_wav(ref_path, sr, audio_np)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–π —Ä–µ—á–∏ —á–µ—Ä–µ–∑ Silero
    base_path = os.path.join(TEMP_DIR, "base_speech.wav")
    silero_model.save_wav(
        text=accented_text,
        speaker=SPEAKER,
        sample_rate=SAMPLE_RATE,
        audio_path=base_path
    )

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ spectral envelope
    tgt_se, _ = se_extractor.get_se(
        ref_path,
        tone_color_converter,
        target_dir=TEMP_COLORS,
        vad=True
    )

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ç–µ–º–±—Ä–∞
    output_path = os.path.join(OUTPUT_DIR, "final_output.wav")
    tone_color_converter.convert(
        audio_src_path=base_path,
        src_se=source_se,
        tgt_se=tgt_se,
        output_path=output_path,
        message="@MyShell"
    )

    return output_path

# --------------------
# Gradio UI
# --------------------
with gr.Blocks(title="OpenVoice RU", theme=gr.themes.Soft()) as demo:
    gr.Markdown("## OpenVoice Clone (–†—É—Å—Å–∫–∏–π)")

    with gr.Row():
        with gr.Column(scale=2):
            text_input = gr.Textbox(label="–¢–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞", placeholder="–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç...")
            accent_button = gr.Button("–†–∞—Å—Å—Ç–∞–≤–∏—Ç—å —É–¥–∞—Ä–µ–Ω–∏—è")
            accented_output = gr.Textbox(label="–¢–µ–∫—Å—Ç —Å —É–¥–∞—Ä–µ–Ω–∏—è–º–∏", interactive=True)
            audio_input = gr.Audio(label="–ê—É–¥–∏–æ-—Ä–µ—Ñ–µ—Ä–µ–Ω—Å (WAV, 5‚Äì15 —Å–µ–∫)", type="numpy")
            gen_button = gr.Button("–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å", variant="primary")
        with gr.Column(scale=1):
            audio_output = gr.Audio(label="–°–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–≤—É–∫")

    accent_button.click(accent_text, inputs=text_input, outputs=accented_output)
    gen_button.click(generate_voice, inputs=[accented_output, audio_input], outputs=audio_output)

if __name__ == "__main__":
    demo.launch(
        share=True,
        enable_queue=True,
        server_name="0.0.0.0",
        server_port=7860
    )

